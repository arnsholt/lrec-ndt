\documentclass[11pt,a4paper]{article}

\usepackage{ctable}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lrec2006}
\usepackage{apacite}
\usepackage{covington}

\bibliographystyle{apacite}

\title{The Norwegian Dependency Treebank}
\author{Folk}

\begin{document}
\maketitle

\section{Introduction (Lilja)}
A syntactic treebank constitutes an important language resource in
establishing a set of natural language processing tools for a
language and may be employed for central tasks such as part-of-speech
tagging and syntactic parsing. For the past decade, dependency
analysis has become an increasinlgy popular form of syntactic analysis
and has been claimed to strike a balance between a depth of analysis
sufficient for many down-stream applications and accuracy and
efficiency in parsing with these types representations. The CoNLL
shared tasks devoted to dependency parsing and joint syntactic and
2semantic parsing,
\cite<see e.g.,>{Niv:Hal:Kub:07,Haj:Cia:Joh:09}, have been instrumental in
establishing a common set of dependency treebanks for a range of
languages such as English, Swedish, Czech and Arabic, \footnote{Note
  that several of the treebanks employed for the shared task were not
  originally dependency treebanks, but rather converted from
  phrase-structure representations.}  thus enabling multilingual evaluation of different systems.  The increased
availability of dependency parsers has spurred down-stream use of
dependency representations in diverse tasks such as Machine Translation \shortcite{Din:Pal:05}, Sentiment Analysis \shortcite{Wil:Wie:Hof:09} and Negation Resolution \shortcite{Lap:Vel:Ovr:12}.

Until recently, there has been no publicly available (dependency)
treebank for Norwegian.\footnote{Possibly comment on INESS?} Hence,
the progress in parsing and applications described above have not been
possible for Norwegian.  At present, however, the Language Bank,
hosted at the Norwegian National Library, is in the process of
completing a two year project with the aim of producing a dependency
treebank for Norwegian. 

In this paper we present the Norwegian Dependency Treebank (NDT), a
syntactic treebank which encompasses treebanks for both variants of
Norwegian (Bokm{\aa}l and Nynorsk)\footnote{On the distinction between
  BM and NN}. In the following, we describe the main annotation
principles employed in the syntactic analysis of the treebank and
discuss the selection of texts. We then go on to describe the
annotation process in some detail. Finally, we present first results
for data-driven dependency parsing of Norwegian.

%311 words

\section{Annotation principles (PE)}
NDT is released in the CoNLL format, a tab-separated table consisting of the following 10 fields: token index, word form, lemma, coarse-grained part-of-speech (POS), fine-grained POS, morphological features, index of head, dependency relation and two fields which are left blank in NDT (\cite{Niv:Hal:Kub:07}). The lemmatization and morphological tagging follows quite closely the Oslo-Bergen Tagger (OBT), but a few adaptions have been made, notably for spelling variants which do not comply for the official norm for Bokmål and Nynorsk (cf. \cite{Joh:Hag:No:Lyn:2011}, \cite{Sol:2013}).


Independent syntactic annotation guidelines have been developed for NDT (<ref> retningslinjene). When developing the annotation guidelines, four fundamental principles had to be taken into consideration: 1. The annotation had to be as linguistically adequate as possible. The Norwegian Reference Grammar (\cite{Faa:Lie:Van:97}) was used as norm. 2. It had to be possible for annotators to implement the analyzes consistently. 3. As the size of the treebank matters for most potential users, the annotators should be able to annotate relatively quickly, without spending too much time pondering over the correct analysis of specific constructions. 4. It should be relatively easy to make queries for specific constructions, using treebank query tools (e.g. TreeQuery <ref>). In what remains of this section, we will show examples of how we tried to implement these principles:

\subsection{Adverbials}
In treebanks comparable to NDT, e.g. the Swedish treebank Talbanken (<ref>), there are separate dependency relations for different types of adverbials, such as time adverbials, manner adverbials and place adverbials. Some treebanks, e.g. PROIEL (<ref>), distinguish between adverbials selected by specific predicates, such as motion verbs, and adverbial modifiers which are not obligatory. There are good linguistic reasons for making such distinctions. However, we found that it would be difficult to do so and at the same time comply with the consistency and time constraints of principle 2 and 3: While it would be obvious to which category many adverbials belong, there would also be a lot of borderline cases. Unless the guidelines contained rules which were clear and easy to follow for such cases,chances are high that an annotator would not be able to annotate similar cases in a uniform manner, and inter-annotator consistency would also be difficult to obtain. And even with such rules in place, annotators would spend a considerable amount of time deliberating which dependency relation to choose. We have therefore chosen a more shallow analysis: All adverbials, regardless of type and of whether or not they are selected, receive a uniform dependency relation - ADV.

\subsection{Transitive and intransitive prepositions}
In some cases the pursuit of linguistic adequacy has been given priority. The sentences (\ref{ex:intrans}) and (\ref{ex:trans}) are an example of such a case:

\begin{examples}
\item\label{ex:intrans}
\gll Per setter på CD-en.
Per puts on CD+the
\glt 'Per puts on the CD.'
\glend

\item\label{ex:trans}
\gll Per sitter på stolen.
Per sits on chair+the
\glt 'Per sits on the chair.'
\glend
\end{examples}

In both (\ref{ex:intrans}) and (\ref{ex:trans}) the preposition \emph{på} is followed by a noun. There are, however, strong reasons for analyzing the sentences differently. In (\ref{ex:trans}), the noun is clearly a complement to the preposition: The preposition and the noun are semantically connected, they behave as a single constituent, and the complement retains its position after the preposition if it is pronominalized. In (\ref{ex:intrans}), on the other hand, there is no obvious semantic connection between the preposition and the noun, the two words don't form a constituent together, and if the noun is pronominalized, it can, and usually will, precede the preposition. In NDT, the noun in (\ref{ex:intrans}) would be made dependent on the verb with the dependency relation for direct objects, DOBJ. The noun in (\ref{ex:trans}) would be made dependent on the preposition with the dependency relation of prepositional complements, PUTFYLL.

Annotators frequently meet preposition-noun sequences which are much less straightforward than in these examples, and they need to deliberate whether one or the other analysis is correct. We have, however, chosen to retain this distinction, to make sure that the analyses are acceptable from a linguistic point of view and also in order to achieve a uniform analysis of sentences such as (\ref{ex:intrans}) and cases where the object noun or pronoun does not follow the intransitive preposition. To ensure consistency and a high annotation speed, the annotation guidelines have a number of syntactic tests which the annotators use to distinguish between the construction (<ref> retningslinjene s 54-56).

\subsection{Complementizers}
There is no obvious head-dependent relationship between complementizers and verbs or between functional and lexical heads in general, and there is therefore not a unique answer to how such a relationship should be represented in Dependency Grammar. In the original formulation of Dependency Grammar, the dependency relations were not used between function words and lexical words, but a different, symmetrical relation (cf. <ref> Tesnière 1965). This is not an option in Dependency Grammar treebanks, however, and treebanks vary with respect to the representation of such relations. In NDT, the verb is the head and the complementizer is a dependent on the verb. This choice is first and foremost motivated by the fourth principle stated above: that it should be easy to make queries for specific constructions. In Norwegian, complementizers are frequently dropped, as the following examples show (from NDT):

\begin{examples}
\item\label{ex:medat}
\gll Nå tror lokale myndigheter at bortføringen var nøye planlagt.
now believe local authorities that.comp abduction+the was carefully planned
\glt 'Local authorities now believe that the abduction was carefully planned.'
\glend

\item\label{ex:utenat}
\gll Jeg tror ikke det er tilfeldig.
I believe not it is accidental
\glt 'I don't belive that it is accidental.'
\glend
\end{examples}
 
Clausal complements to verbs such as \emph{tro}, 'believe', occur both with the complementizer \emph{at}, as in (\ref{ex:medat}), and without any complementizer, as in (\ref{ex:utenat}). If the complementizer were the head, the complement clauses in (\ref{ex:medat}) and (\ref{ex:utenat}) would have had different heads, despite their obvious similarities. This, in turn, would make it significantly more difficult to formulate queries in e.g. TreeQuery, which cover both cases. The ability to retrieve constructions through queries has been important in the annotation process, notably in order to find annotation errors, and it will probably also be important to certain users of the treebank. In NDT, sentences such as (\ref{ex:medat}) and (\ref{ex:utenat}) are analyzed similarly: The (finite) verb of the clausal complement serves as head in both cases, and carry the dependency relation DOBJ (direct object), c.f. <figure 1 + 2>. Both will therefore be retrieved through a query for finite verbs with the dependency relation DOBJ.

%<figure 1> - analysis of {ex:medat}

%<figure 2> - analysis of {ex:utenat}

\section{Texts}
NDT currently consist of 282 000 tokens of Norwegian Bokmål and 263 000 tokens of Norwegian Nynorsk, but these numbers will grow somewhat until the end of the project period in January 2014. Comparable treebanks such as the Prague Dependency Treebank and the TIGER treebank, contain 

\ctable[botcap,
    caption={Statistics for texts in the Bokmål section. Number of sentences,
    tokens and non-projective edges/sentences.},
    label=tbl:stats-bm
]{lrrr@{/}l}{}{
        \FL
        Source          & Sent. & Tok.   & \multicolumn{2}{c}{Non-proj.} \ML
        Aftenposten     &  5646 &  92313 & 1497&1212 \NN
        Blogg           &   706 &  22330 &  188&146  \NN
        Bergens Tidende &  2551 &  38900 &  459&393  \NN
        Dagbladet       &  4436 &  60720 &  763&643  \NN
        Klassekampen    &   919 &  16486 &  247&194  \NN
        NOU             &   477 &   8360 &  116&91   \NN
        Sunnmørsposten  &  1201 &  19109 &  288&252  \NN
        Storting        &  1280 &  22146 &  432&315  \NN
        VG              &   868 &  12821 &  149&128  \ML
        Total           & 18084 & 282075 & 4139&3374
        \LL
    }

\ctable[botcap,
    caption={Statistics for texts in the Nynorsk section. Number of sentences,
    tokens and non-projective edges/sentences.},
    label=tbl:stats-nn
]{lrrr@{/}l}{}{
        \FL
        Source             & Sent. & Tok.   & \multicolumn{2}{c}{Non-proj.} \ML
        Blogg              &   579 &   9676 &  172&125  \NN
        Dag og Tid         &  5278 &  88982 & 1305&1063 \NN
        Firda              &  3401 &  50579 &  628&524  \NN
        Klassekampen       &  2215 &  39739 &  553&460  \NN
        Mål og Meining     &   976 &  25113 &  552&371  \NN
        Vest-Telemark blad &  2956 &  46990 &  674&567  \ML
        Total              & 15405 & 263079 & 3884&3110
        \LL
    }


Commodo voluptate laboris, dolor Tonx whatever trust fund. Salvia cliche plaid
Brooklyn, veniam Terry Richardson cardigan slow-carb craft beer ullamco
tattooed. Wayfarers id banh mi jean shorts ex deserunt. Master cleanse beard
minim whatever. Non farm-to-table organic duis. Truffaut Neutra sriracha,
ethnic adipisicing put a bird on it eiusmod Helvetica keffiyeh American
Apparel cred selvage. Keffiyeh chia banjo Banksy laborum odio twee, craft beer
labore gentrify salvia pour-over jean shorts Echo Park PBR.

\section{Annotation process}
\subsection{Annotators and annotation work flow}
\subsection{Preprocessing}
\subsection{Syntactic preprocessing (Arne)}
\ctable[botcap,
    caption={Preprocessor accuracies. Unlabeled (UAS) and Labeled (LAS)
    attachment scores, and label accuracies (Labels).},
    label=tbl:parsers,
    notespar,
]{lr@{.}lr@{.}lr@{.}l}{Table too wide. Maybe abbreviate citation to something
like ``S and Ø (2012)''?}{
        \FL
Parser & \multicolumn{2}{c}{UAS} & \multicolumn{2}{c}{LAS} & \multicolumn{2}{c}{Labels} \ML
CG (BM) & 79&39\% & 72&45\% & 82&10\% \NN
CG (NN) & 80&16\% & 74&76\% & 84&84\% \NN
\citeA{Skj:Ovr12} (BM) & 87&54\% & 84&63\% & 89&63\%
        \LL
    }

\subsection{Inter-annotator agreement (Arne)}

\section{Dependency parsing (Arne \& Lilja)}
An important aspect of treebank annotation relates to its \emph{parsability},
i.e. the quality of syntactic parsers that can be acquired based on
the treebank data.  In order to investigate the parser quality we can
expect from NDT, we have evaluated three state-of-the-art dependency
parsers on the material: Maltparser \shortcite{Niv:Hal:Nil:06},
MST-parser \shortcite{McD:Per:Rib:Haj:05} and the parser of
\citeA{Boh:Niv:12}.  

For these experiments, both portions of the treebank (Bokm{\aa}l and
Nynorsk) were split into 80-10-10 train, development and test sets.
Standard evaluation metrics in dependency parsing are unlabeled and
labeled attachment scores (UAS, LAS; implemented by the CoNLL
\textsf{eval.pl} scorer).  These measure the proportion of tokens
which are correctly attached to their head token and, for LAS,
furthermore have been assigned the correct dependency label.

%121 words


\begin{table}
\centering
\begin{tabular}{lll|ll}
\hline
& \multicolumn{2}{c}{Bokm{\aa}l} & \multicolumn{2}{c}{Nynorsk}\\
 & UAS & LAS  & UAS & LAS \\\hline
Malt default & 88.27 & 85.03 & 87.54 & 83.82\\
Malt optimized & 92.19 & 89.82 & 91.57 & 88.98\\\hline
\end{tabular}
\caption{Dependency parsing results for NDT}
  \label{tb:parsing}
\end{table}

Table \ref{tb:parsing} presents the dependency parsing results
obtained for NDT.  For Maltparser, we trained two versions of the
parser: one version with default settings and one optimized version,
where the parser settings was optimized using the MaltOptimizer
software \shortcite{Bal:Niv:12}.


%\newpage
%\onecolumn
\clearpage
\bibliography{ndt}

\end{document}
